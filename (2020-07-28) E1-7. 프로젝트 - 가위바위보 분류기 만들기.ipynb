{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-7. 프로젝트: 가위바위보 분류기 만들기   \n",
    "   \n",
    "* training set(총 2341장): 김윤경님 + 강종구(2차) + 이영빈님(2차) + 홍진표님(2차) + 이영빈님(3차) \n",
    "* test set(총 300장): 홍진표님(1차) \n",
    "* epochs: 10\n",
    "\n",
    "첫 번째 Exploration Stage에서는 가위바위보 분류기를 만들었다.\n",
    "\n",
    "실습에서 해본 0~9 숫자 분류 모델의 input_shape 중 3번째 파라미터를 흑백(1)을 RGB(3)로 변경했다. 마지막 Dense의 첫 파라미터가 최종 분류기의 클래스 수임을 알게 되어 3(가위, 바위, 보)으로 변경했다. 아직 Sequential Model의 내용을 정확히 이해할 수는 없지만, 파라미터 값을 바꿀 때마다 accuracy가 달라짐을 확인했다.   \n",
    "   \n",
    "트레이닝 시에는 영향을 끼치는 몇 가지 요인이 있었다. 첫째, 데이터가 되는 손 사진을 말끔한 벽을 뒤에 두고 찍어 손과 배경이 명확히 구분되도록 하면 정확도가 올라갔다. 둘째, 조원들의 사진과 슬랙에 공유된 사진을 모아 training data의 양이 많아질수록 정확도가 올라갔다. 테스트 데이터 역시 트레이닝 데이터와 비슷한 환경에서 찍힌 것이어야 모델이 인식을 잘 하는 것으로 보인다.\n",
    "\n",
    "---\n",
    "\n",
    "<테스트 결과>\n",
    "* 1차 테스트\n",
    "```\n",
    "10/10 - 2s - loss: 2.7910 - accuracy: 0.6900\n",
    "test_loss: 2.790980339050293 \n",
    "test_accuracy: 0.6899999976158142\n",
    "```\n",
    "* 2차 테스트\n",
    "```\n",
    "10/10 - 2s - loss: 2.2659 - accuracy: 0.6667\n",
    "test_loss: 2.265941619873047 \n",
    "test_accuracy: 0.6666666865348816\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "import numpy as np\n",
    "\n",
    "training_filetype = \"JPEG\"\n",
    "training_endswith = \".jpg\"\n",
    "\n",
    "test_filetype = \"JPEG\"\n",
    "test_endswith = \".jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 준비하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기 + resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (7.2.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow\n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 변환 (이미 되어있으므로 생략)\n",
    "'''\n",
    "img_dirs = [{'name': \"scissor\", 'path': \"/aiffel/rock_scissor_paper/scissor\"},\n",
    "        {'name': \"rock\", 'path': \"/aiffel/rock_scissor_paper/rock\"},\n",
    "        {'name': \"paper\", 'path': \"/aiffel/rock_scissor_paper/paper\"}]\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    print(\"현재 이미지 종류: \" + img_dir['name'])\n",
    "    curr_path = os.getenv(\"HOME\") + img_dir['path']\n",
    "    print(\">> 이미지 디렉토리 경로: \", img_dir['path'])\n",
    "\n",
    "    images = glob.glob(curr_path + \"/*\" + training_endswith)\n",
    "    \n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, training_filetype)\n",
    "    \n",
    "    print(\"* resize completed: \" + img_dir['name'] + \" (\" str(len(images)) + \")\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2341 입니다.\n",
      "x_train shape: (2341, 28, 28, 3)\n",
      "y_train shape: (2341,)\n"
     ]
    }
   ],
   "source": [
    "def load_training_data(img_path, file_endswith):\n",
    "    # 가위: 0 / 바위: 1 / 보: 2\n",
    "    number_of_data = 2341\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    \n",
    "    # 이미지 데이터와 라벨 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path + '/scissor/*' + file_endswith):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0   # 가위 : 0\n",
    "        idx = idx + 1\n",
    "        \n",
    "    for file in glob.iglob(img_path + '/rock/*' + file_endswith):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1   # 바위 : 1\n",
    "        idx = idx + 1\n",
    "        \n",
    "    for file in glob.iglob(img_path + '/paper/*' + file_endswith):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2   # 보 : 2\n",
    "        idx = idx + 1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx, \"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path_training = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/train_retake_combined\"\n",
    "(x_train, y_train)=load_training_data(image_dir_path_training, training_endswith)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 불러졌는지 확인\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                12816     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 17,955\n",
      "Trainable params: 17,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "74/74 [==============================] - 4s 51ms/step - loss: 2.4004 - accuracy: 0.4648\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.7206\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.8120\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2615 - accuracy: 0.9052\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.9158\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9398\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9522\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9569\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb44810f810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 얼마나 잘 만들었는지 확인하기 (테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 변환 (이미 되어있으므로 생략)\n",
    "'''\n",
    "img_dirs = [{'name': \"scissor\", 'path': \"/aiffel/rock_scissor_paper/test/scissor\"},\n",
    "        {'name': \"rock\", 'path': \"/aiffel/rock_scissor_paper/test/rock\"},\n",
    "        {'name': \"paper\", 'path': \"/aiffel/rock_scissor_paper/test/paper\"}]\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    print(\"현재 이미지 종류: \" + img_dir['name'])\n",
    "    curr_path = os.getenv(\"HOME\") + img_dir['path']\n",
    "    print(\">> 이미지 디렉토리 경로: \", img_dir['path'])\n",
    "\n",
    "    images = glob.glob(curr_path + \"/*\" + test_endswith)\n",
    "    \n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, test_filetype)\n",
    "    \n",
    "    print(\"* resize completed: \" + img_dir['name'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_test_data(img_path, file_endswith):\n",
    "    number_of_data = 300\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    \n",
    "    # 이미지 데이터와 라벨 데이터를 담을 행렬(matrix) 영역 생성\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path + '/scissor/*' + file_endswith):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0   # 가위 : 0\n",
    "        idx = idx + 1\n",
    "        \n",
    "    for file in glob.iglob(img_path + '/rock/*' + file_endswith):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1   # 바위 : 1\n",
    "        idx = idx + 1\n",
    "        \n",
    "    for file in glob.iglob(img_path + '/paper/*' + file_endswith):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2   # 보 : 2\n",
    "        idx = idx + 1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx, \"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path_test = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/jp1\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path_test, test_endswith)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 2s - loss: 2.2659 - accuracy: 0.6667\n",
      "test_loss: 2.265941619873047 \n",
      "test_accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
