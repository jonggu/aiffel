{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD14. 추론하는 인공지능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경에 맞게 경로 수정\n",
    "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(path) as tar:\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경에 맞게 경로 수정\n",
    "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 전처리\n",
    "* 데이터를 읽는 과정에서 스토리, 질문, 답변을 각각 분리 (supporting fact는 저장 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하고 출력해보기\n",
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)\n",
    "\n",
    "# train data: 10000개\n",
    "print(len(train_stories))\n",
    "print(len(train_questions))\n",
    "print(len(train_answers))\n",
    "\n",
    "# test data: 1000개\n",
    "print(len(test_stories))\n",
    "print(len(test_questions))\n",
    "print(len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 스토리 출력해보기\n",
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 5개 질문 출력해보기\n",
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 5개 답변 출력해보기\n",
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰화\n",
    "* 파이썬 버전에 따라 다르게 사용: https://github.com/keras-team/keras/issues/13248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 버전에 따라 다르게 사용\n",
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.sub(r\"\\s+|\\b\", '\\f', sent).split('\\f') if x.strip() ] # python 3.7의 경우 \n",
    "    # return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()] # python 3.6의 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주요 전처리 작업\n",
    "    - 단어장 생성\n",
    "    - 단어에서 정수로, 정수에서 단어로 맵핑하는 딕셔너리 생성\n",
    "    - 그 과정에서 스토리와 질문의 가장 긴 거리 구하기\n",
    "* 위 과정에서, 같은 스토리 내 여러 문장을 하나의 문장으로 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수를 사용해 가장 긴 샘플의 길이 리턴\n",
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어장 출력해보기\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 변수로 사용할 단어장의 크기는 +1 (패딩 고려)\n",
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩, 정수 인코딩, 벡터화\n",
    "* `vectorize()`\n",
    "    - 현재 각 데이터는 전부 텍스트 데이터입니다. 이를 단어와 맵핑되는 정수로 인코딩해줍니다. 이 과정은 앞서 만들어놓은 word2idx를 활용합니다.\n",
    "    - 스토리와 질문 데이터에 대해서 각각의 최대 길이로 패딩(padding)합니다. 이 과정은 앞서 계산해놓은 story_max_len과 question_max_len을 사용합니다.\n",
    "    - 레이블에 해당되는 정답 데이터를 원-핫 인코딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터에 벡터화 수행\n",
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 결과의 크기 (shape) 확인\n",
    "# (10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n",
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메모리 네트워크 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 하이퍼파라미터 정의\n",
    "\n",
    "train_epochs = 120 # 에포크 횟수\n",
    "batch_size = 32 # 배치 크기\n",
    "embed_size = 50 # 임베딩 크기\n",
    "lstm_size = 64 # LSTM의 크기\n",
    "dropout_rate = 0.30 # 과적합 방지 기법인 드롭아웃 적용 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력을 담아두는 변수 정의\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = 'babi_memory_net/model.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 정확도 출력\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 과정에서 기록해두었던 훈련 데이터, 검증 데이터의 정확도와 loss를 그래프로 출력\n",
    "\n",
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 문제를 잘 맞추고 있는지 임의로 30개의 예측 결과 출력해보기\n",
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:7} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트: 한국어 QA 모델 만들기\n",
    "* `e-28-korean.zip`: bAbI 데이터셋을 저자가 한국어로 변환한 한국어 버전의 bAbI 데이터셋 (https://wikidocs.net/85470)\n",
    "   \n",
    "> **주의** 기존 케라스 공식 문서의 babi_rnn, babi_memn 구현은 파이썬 3.6을 기준으로 하고 있으며, 파이썬 3.7에서는 정상동작 하지 않을 수 있습니다. 실습 시 참고하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'e-28-korean'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test_kor.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 필웅이는 화장실로 갔습니다.\n",
      "2 은경이는 복도로 이동했습니다.\n",
      "3 필웅이는 어디야? \t화장실\t1\n",
      "4 수종이는 복도로 복귀했습니다.\n",
      "5 경임이는 정원으로 갔습니다.\n",
      "6 수종이는 어디야? \t복도\t4\n",
      "7 은경이는 사무실로 갔습니다.\n",
      "8 경임이는 화장실로 뛰어갔습니다.\n",
      "9 수종이는 어디야? \t복도\t4\n",
      "10 필웅이는 복도로 갔습니다.\n",
      "11 수종이는 사무실로 가버렸습니다.\n",
      "12 수종이는 어디야? \t사무실\t11\n",
      "13 은경이는 정원으로 복귀했습니다.\n",
      "14 은경이는 침실로 갔습니다.\n",
      "15 경임이는 어디야? \t화장실\t8\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29985\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 전체 수 확인\n",
    "total_count = 0\n",
    "\n",
    "for line in lines:\n",
    "    total_count += 1\n",
    "    \n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "        \n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)\n",
    "\n",
    "# 저장하고 출력해보기\n",
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)\n",
    "\n",
    "# train data: 10000개\n",
    "print(len(train_stories))\n",
    "print(len(train_questions))\n",
    "print(len(train_answers))\n",
    "\n",
    "# test data: 1000개\n",
    "print(len(test_stories))\n",
    "print(len(test_questions))\n",
    "print(len(test_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['필웅이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '수종이는 어디야? ', '경임이는 어디야? ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상위 5개 질문 출력해보기\n",
    "train_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['화장실', '복도', '복도', '사무실', '화장실']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상위 5개 답변 출력해보기\n",
    "train_answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['수종이는 화장실로 뛰어갔습니다.',\n",
       " '경임이는 사무실로 갔습니다.',\n",
       " '은경이는 부엌으로 이동했습니다.',\n",
       " '경임이는 화장실로 갔습니다.',\n",
       " '수종이는 복도로 갔습니다.',\n",
       " '필웅이는 부엌으로 가버렸습니다.',\n",
       " '수종이는 부엌으로 이동했습니다.',\n",
       " '수종이는 화장실로 가버렸습니다.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 스토리 출력해보기\n",
    "train_stories[3878]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토크나이저 변경하기 (중요)\n",
    "* 사람 이름 등을 위해 사용자 사전 추가: Customized Konlpy https://inspiringpeople.github.io/data%20analysis/ckonlpy/\n",
    "   \n",
    "```\n",
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.morphs('은경이는 사무실로 갔습니다.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('필웅이', 'Noun')\n",
    "twitter.add_dictionary('수종이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Noun')\n",
    "\n",
    "# twitter.morhps('은경이는 정원으로 복귀했습니다.')\n",
    "# twitter.morphs('수종이는 어디야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return twitter.morphs(sent) # 형태소 분석기로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "    \n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "    \n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어장 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석 후 불용어 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수를 사용해 가장 긴 샘플의 길이 리턴\n",
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'는': 1, '.': 2, '로': 3, '했습니다': 4, '으로': 5, '경임이': 6, '은경이': 7, '수종이': 8, '필웅이': 9, '이동': 10, '가버렸습니다': 11, '뛰어갔습니다': 12, '복귀': 13, '화장실': 14, '정원': 15, '복도': 16, '갔습니다': 17, '사무실': 18, '부엌': 19, '침실': 20, '어디': 21, '야': 22, '?': 23}\n"
     ]
    }
   ],
   "source": [
    "# 단어장 출력해보기\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 변수로 사용할 단어장의 크기는 +1 (패딩 고려)\n",
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 70\n",
      "질문의 최대 길이 : 5\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "    # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "    # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터에 벡터화 수행\n",
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 70) (10000, 5) (10000, 24) (1000, 70) (1000, 5) (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "# 변환된 결과의 크기 (shape) 확인\n",
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어에서의 모델 정확도 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 하이퍼파라미터 정의\n",
    "\n",
    "train_epochs = 120 # 에포크 횟수\n",
    "batch_size = 32 # 배치 크기\n",
    "embed_size = 50 # 임베딩 크기\n",
    "lstm_size = 64 # LSTM의 크기\n",
    "dropout_rate = 0.30 # 과적합 방지 기법인 드롭아웃 적용 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : Tensor(\"input_1:0\", shape=(None, 70), dtype=float32)\n",
      "Question: Tensor(\"input_2:0\", shape=(None, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 입력을 담아두는 변수 정의\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    " \n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embed_size) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    " \n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embed_size) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m Tensor(\"sequential/dropout/cond/Identity:0\", shape=(None, 70, 50), dtype=float32)\n",
      "Input encoded c Tensor(\"sequential_1/dropout_1/cond/Identity:0\", shape=(None, 70, 5), dtype=float32)\n",
      "Question encoded Tensor(\"sequential_2/dropout_2/cond/Identity:0\", shape=(None, 5, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape Tensor(\"activation/truediv:0\", shape=(None, 70, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response shape Tensor(\"permute/transpose:0\", shape=(None, 5, 70), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 매칭 유사도 행렬과 질문에 대한 임베딩을 더한다.\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, question_max_len)\n",
    "response = Permute((2, 1))(response)  # (samples, question_max_len, story_maxlen)\n",
    "print('Response shape', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer shape Tensor(\"concatenate/concat:0\", shape=(None, 5, 120), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# concatenate the response vector with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    " \n",
    "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8909 - acc: 0.1718 - val_loss: 1.7920 - val_acc: 0.1490\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7065 - acc: 0.2572 - val_loss: 1.6746 - val_acc: 0.2740\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6316 - acc: 0.3112 - val_loss: 1.5773 - val_acc: 0.3450\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5281 - acc: 0.4015 - val_loss: 1.4439 - val_acc: 0.4640\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4565 - acc: 0.4451 - val_loss: 1.4206 - val_acc: 0.4740\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4069 - acc: 0.4593 - val_loss: 1.3906 - val_acc: 0.4860\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3689 - acc: 0.4749 - val_loss: 1.3375 - val_acc: 0.4980\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3451 - acc: 0.4839 - val_loss: 1.3264 - val_acc: 0.5060\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3261 - acc: 0.4836 - val_loss: 1.3029 - val_acc: 0.5100\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3029 - acc: 0.4984 - val_loss: 1.2885 - val_acc: 0.5080\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2765 - acc: 0.5112 - val_loss: 1.2817 - val_acc: 0.5140\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2608 - acc: 0.5087 - val_loss: 1.2607 - val_acc: 0.5150\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2438 - acc: 0.5198 - val_loss: 1.2689 - val_acc: 0.5160\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2278 - acc: 0.5246 - val_loss: 1.2729 - val_acc: 0.5010\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2194 - acc: 0.5208 - val_loss: 1.2456 - val_acc: 0.5150\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.2095 - acc: 0.5188 - val_loss: 1.2417 - val_acc: 0.5120\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1900 - acc: 0.5284 - val_loss: 1.2148 - val_acc: 0.5090\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1807 - acc: 0.5287 - val_loss: 1.2152 - val_acc: 0.5190\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1601 - acc: 0.5412 - val_loss: 1.2036 - val_acc: 0.5210\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1560 - acc: 0.5301 - val_loss: 1.1944 - val_acc: 0.5300\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1467 - acc: 0.5298 - val_loss: 1.1723 - val_acc: 0.5170\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1238 - acc: 0.5366 - val_loss: 1.1942 - val_acc: 0.5120\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1201 - acc: 0.5388 - val_loss: 1.1525 - val_acc: 0.5260\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1118 - acc: 0.5410 - val_loss: 1.1611 - val_acc: 0.5220\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.1016 - acc: 0.5354 - val_loss: 1.1676 - val_acc: 0.5160\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0908 - acc: 0.5461 - val_loss: 1.1635 - val_acc: 0.5100\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0924 - acc: 0.5428 - val_loss: 1.2222 - val_acc: 0.5020\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0781 - acc: 0.5494 - val_loss: 1.1634 - val_acc: 0.4940\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0724 - acc: 0.5487 - val_loss: 1.1745 - val_acc: 0.5080\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0640 - acc: 0.5467 - val_loss: 1.1721 - val_acc: 0.5160\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0500 - acc: 0.5541 - val_loss: 1.1893 - val_acc: 0.4810\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0509 - acc: 0.5556 - val_loss: 1.1927 - val_acc: 0.5040\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0430 - acc: 0.5582 - val_loss: 1.1651 - val_acc: 0.5010\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0383 - acc: 0.5595 - val_loss: 1.1704 - val_acc: 0.4990\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0276 - acc: 0.5630 - val_loss: 1.1599 - val_acc: 0.4950\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0227 - acc: 0.5700 - val_loss: 1.1529 - val_acc: 0.5080\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0098 - acc: 0.5714 - val_loss: 1.1676 - val_acc: 0.5010\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.0005 - acc: 0.5822 - val_loss: 1.1672 - val_acc: 0.5050\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9798 - acc: 0.5931 - val_loss: 1.1412 - val_acc: 0.5470\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9451 - acc: 0.6191 - val_loss: 1.0900 - val_acc: 0.5720\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9016 - acc: 0.6449 - val_loss: 1.0122 - val_acc: 0.6090\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7923 - acc: 0.6985 - val_loss: 0.8168 - val_acc: 0.6920\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6443 - acc: 0.7710 - val_loss: 0.6958 - val_acc: 0.7540\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5470 - acc: 0.8001 - val_loss: 0.5883 - val_acc: 0.7880\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4930 - acc: 0.8195 - val_loss: 0.5174 - val_acc: 0.8090\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4308 - acc: 0.8418 - val_loss: 0.4750 - val_acc: 0.8170\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3954 - acc: 0.8569 - val_loss: 0.4281 - val_acc: 0.8410\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3530 - acc: 0.8716 - val_loss: 0.3915 - val_acc: 0.8540\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3279 - acc: 0.8804 - val_loss: 0.3990 - val_acc: 0.8480\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3085 - acc: 0.8876 - val_loss: 0.3825 - val_acc: 0.8590\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2949 - acc: 0.8940 - val_loss: 0.3464 - val_acc: 0.8770\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2726 - acc: 0.8978 - val_loss: 0.3518 - val_acc: 0.8730\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2617 - acc: 0.9019 - val_loss: 0.3328 - val_acc: 0.8740\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2543 - acc: 0.9068 - val_loss: 0.3267 - val_acc: 0.8750\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2376 - acc: 0.9132 - val_loss: 0.3482 - val_acc: 0.8630\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2231 - acc: 0.9178 - val_loss: 0.3173 - val_acc: 0.8790\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2082 - acc: 0.9227 - val_loss: 0.3022 - val_acc: 0.8820\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1964 - acc: 0.9269 - val_loss: 0.2765 - val_acc: 0.8970\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1831 - acc: 0.9325 - val_loss: 0.2716 - val_acc: 0.9070\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1610 - acc: 0.9433 - val_loss: 0.2327 - val_acc: 0.9120\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1496 - acc: 0.9486 - val_loss: 0.2258 - val_acc: 0.9200\n",
      "Epoch 62/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1384 - acc: 0.9494 - val_loss: 0.2187 - val_acc: 0.9210\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1257 - acc: 0.9554 - val_loss: 0.2883 - val_acc: 0.9130\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1161 - acc: 0.9580 - val_loss: 0.2076 - val_acc: 0.9170\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1141 - acc: 0.9600 - val_loss: 0.2171 - val_acc: 0.9220\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1107 - acc: 0.9611 - val_loss: 0.1897 - val_acc: 0.9320\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0954 - acc: 0.9661 - val_loss: 0.2189 - val_acc: 0.9340\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0887 - acc: 0.9704 - val_loss: 0.2031 - val_acc: 0.9330\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0911 - acc: 0.9682 - val_loss: 0.2110 - val_acc: 0.9250\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0901 - acc: 0.9692 - val_loss: 0.1851 - val_acc: 0.9360\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0783 - acc: 0.9739 - val_loss: 0.1911 - val_acc: 0.9340\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0754 - acc: 0.9725 - val_loss: 0.2210 - val_acc: 0.9270\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0717 - acc: 0.9748 - val_loss: 0.1936 - val_acc: 0.9370\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0632 - acc: 0.9781 - val_loss: 0.2337 - val_acc: 0.9320\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0619 - acc: 0.9794 - val_loss: 0.1974 - val_acc: 0.9410\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0578 - acc: 0.9802 - val_loss: 0.2269 - val_acc: 0.9420\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0597 - acc: 0.9802 - val_loss: 0.1969 - val_acc: 0.9390\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0536 - acc: 0.9821 - val_loss: 0.2095 - val_acc: 0.9410\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0565 - acc: 0.9813 - val_loss: 0.2005 - val_acc: 0.9390\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0526 - acc: 0.9840 - val_loss: 0.1955 - val_acc: 0.9370\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0486 - acc: 0.9832 - val_loss: 0.2121 - val_acc: 0.9440\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0456 - acc: 0.9848 - val_loss: 0.2203 - val_acc: 0.9390\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0403 - acc: 0.9869 - val_loss: 0.2304 - val_acc: 0.9350\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0417 - acc: 0.9858 - val_loss: 0.2175 - val_acc: 0.9390\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0435 - acc: 0.9856 - val_loss: 0.1882 - val_acc: 0.9470\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0426 - acc: 0.9868 - val_loss: 0.2102 - val_acc: 0.9440\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0398 - acc: 0.9873 - val_loss: 0.2119 - val_acc: 0.9430\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0362 - acc: 0.9879 - val_loss: 0.2156 - val_acc: 0.9400\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0361 - acc: 0.9893 - val_loss: 0.2305 - val_acc: 0.9420\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0418 - acc: 0.9873 - val_loss: 0.2180 - val_acc: 0.9450\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0361 - acc: 0.9876 - val_loss: 0.2050 - val_acc: 0.9430\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0319 - acc: 0.9907 - val_loss: 0.2000 - val_acc: 0.9430\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0338 - acc: 0.9902 - val_loss: 0.2104 - val_acc: 0.9440\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0346 - acc: 0.9882 - val_loss: 0.2070 - val_acc: 0.9420\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0335 - acc: 0.9894 - val_loss: 0.2193 - val_acc: 0.9450\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0318 - acc: 0.9900 - val_loss: 0.1953 - val_acc: 0.9470\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0298 - acc: 0.9906 - val_loss: 0.2184 - val_acc: 0.9460\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0267 - acc: 0.9914 - val_loss: 0.2182 - val_acc: 0.9480\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0264 - acc: 0.9918 - val_loss: 0.2270 - val_acc: 0.9420\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0297 - acc: 0.9906 - val_loss: 0.2244 - val_acc: 0.9430\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0268 - acc: 0.9913 - val_loss: 0.2123 - val_acc: 0.9510\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0328 - acc: 0.9905 - val_loss: 0.2070 - val_acc: 0.9500\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0235 - acc: 0.9928 - val_loss: 0.2081 - val_acc: 0.9530\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0243 - acc: 0.9915 - val_loss: 0.1934 - val_acc: 0.9500\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0251 - acc: 0.9926 - val_loss: 0.2214 - val_acc: 0.9470\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0210 - acc: 0.9935 - val_loss: 0.1975 - val_acc: 0.9580\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0307 - acc: 0.9918 - val_loss: 0.2008 - val_acc: 0.9550\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0277 - acc: 0.9920 - val_loss: 0.1855 - val_acc: 0.9520\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0225 - acc: 0.9929 - val_loss: 0.1902 - val_acc: 0.9530\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0265 - acc: 0.9924 - val_loss: 0.2195 - val_acc: 0.9530\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0323 - acc: 0.9915 - val_loss: 0.1861 - val_acc: 0.9550\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0172 - acc: 0.9950 - val_loss: 0.1753 - val_acc: 0.9530\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0194 - acc: 0.9941 - val_loss: 0.2021 - val_acc: 0.9510\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0191 - acc: 0.9946 - val_loss: 0.1873 - val_acc: 0.9510\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0209 - acc: 0.9929 - val_loss: 0.2239 - val_acc: 0.9500\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0186 - acc: 0.9935 - val_loss: 0.2178 - val_acc: 0.9510\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0194 - acc: 0.9939 - val_loss: 0.2106 - val_acc: 0.9520\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0193 - acc: 0.9938 - val_loss: 0.2069 - val_acc: 0.9570\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0187 - acc: 0.9936 - val_loss: 0.2088 - val_acc: 0.9530\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.1819 - val_acc: 0.9560\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "# 테스트 데이터를 검증 데이터로 사용하면서 모델 훈련 시작\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    " \n",
    "# 훈련 후에는 모델 저장\n",
    "model_path = 'babi_memory_net/model_ko.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1819 - acc: 0.9560\n",
      "\n",
      " 테스트 정확도: 0.9560\n"
     ]
    }
   ],
   "source": [
    "# 테스트 정확도 출력\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 과정에서 기록해두었던 훈련 데이터, 검증 데이터의 정확도와 loss를 그래프로 출력\n",
    "\n",
    "# plot accuracy and loss plot\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# labels\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "# get predictions\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문                |실제값  |예측값\n",
      "---------------------------------------\n",
      "은경이 는 어디 야 ?        : 복도      복도\n",
      "필웅이 는 어디 야 ?        : 화장실     화장실\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 부엌      부엌\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 복도      복도\n",
      "경임이 는 어디 야 ?        : 사무실     사무실\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "필웅이 는 어디 야 ?        : 부엌      부엌\n",
      "필웅이 는 어디 야 ?        : 정원      정원\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "은경이 는 어디 야 ?        : 정원      정원\n",
      "은경이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 사무실     사무실\n",
      "은경이 는 어디 야 ?        : 부엌      복도\n",
      "필웅이 는 어디 야 ?        : 복도      복도\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "은경이 는 어디 야 ?        : 사무실     사무실\n",
      "경임이 는 어디 야 ?        : 복도      복도\n",
      "수종이 는 어디 야 ?        : 침실      침실\n",
      "경임이 는 어디 야 ?        : 침실      침실\n",
      "필웅이 는 어디 야 ?        : 침실      침실\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n",
      "수종이 는 어디 야 ?        : 부엌      부엌\n"
     ]
    }
   ],
   "source": [
    "# 실제로 문제를 잘 맞추고 있는지 임의로 30개의 예측 결과 출력해보기\n",
    "NUM_DISPLAY = 30\n",
    "\n",
    "print(\"{:18}|{:5}|{}\".format(\"질문\", \"실제값\", \"예측값\"))\n",
    "print(39 * \"-\")\n",
    "\n",
    "for i in range(NUM_DISPLAY):\n",
    "    question = \" \".join([idx2word[x] for x in Xqtest[i].tolist()])\n",
    "    label = idx2word[ytest[i]]\n",
    "    prediction = idx2word[ytest_[i]]\n",
    "    print(\"{:20}: {:7} {}\".format(question, label, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론\n",
    "* 토큰화에는 konlpy의 Twitter 형태소 분석기를 사용하였다.\n",
    "* customized konlpy를 이용해, 데이터셋에서 잘못 인식할 만한 사람 이름 (필웅이, 은경이, 경임이, 수종이) 을 dictionary에 추가하였다.\n",
    "* 불용어는 따로 제거하지 않았다.\n",
    "* 하이퍼파라미터는 실습과 똑같이 진행하였다. (120 epochs, batch size 32, embedding size 50, lstm size 64, dropout rate 0.3)\n",
    "* 불용어 제거 없이도 정확도가 95.6% 나오고, 그래프도 안정적인 편이어서 프로젝트를 종료했다. 임의의 30개 질문에 대해 예측 결과와 실제 값을 비교해봐도 29개는 맞는 값을 도출하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
